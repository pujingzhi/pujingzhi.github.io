---
title: Jingzhi Pu
subtitle: Associate Professor
description: |
  [Theoretical and Computational Chemistry Lab](https://pujingzhi.github.io/)<br>
  Department of Chemistry and Chemical Biology<br>
  Indiana University Indianapolis<br>
  Indianapolis, IN, USA
  
  [[LD 326](https://maps.app.goo.gl/gsY6GJxhxzBsWk1H7)] &ensp; [[jpu@iu.edu](mailto:jpu@iu.edu)] &ensp; [[CV](./files/AliSiahkoohi-CV.pdf)] &ensp; [[GitHub](https://github.com/pujingzhi)] &ensp; [[Google Scholar](https://scholar.google.com/citations?user=RlYang0AAAAJ&hl=en)]

navbar: false
about:
  id: heading
  template: solana
  image: files/jpu_photo.png
  image-shape: round
  image-width: 215px
---

:::{#heading}
:::


## Background

- Associate Professor, Indiana University Indianapolis (2017--present)
- Postdoc, Harvard University (2005--2010)
- Postdoc, University of Minnesota (2004--2005)
- Ph.D., University of Minnesota, Theoretical and Computational Chemistry (2004)
- B.Sc., Peking University, Chemistry (1999)


## Research

My research focuses on uncertainty quantification in complex systems that arise in computational science and engineering. To this end, my group integrates generative modeling with scientific computing to develop scalable sampling techniques for high-dimensional distributions. This work enables Bayesian inference in large-scale PDE-based inverse problems (e.g., seismic and medical imaging) and provides a principled framework for building reliable, uncertainty-aware AI models for real-world applications.


## Teaching

- [C362 - Physical Chemistry of Molecules] (Fall 2025)

## Publications

### Preprints

**Improving fairness and mitigating MADness in generative models**  
P. M. Mayer, L. Luzi, A. Siahkoohi, D. H. Johnson, and R. G. Baraniuk  
2024.  
[[pdf](https://arxiv.org/abs/2405.13977)]
[[code](https://github.com/alisiahkoohi/torchhyper)]
[[slides](https://www.dropbox.com/scl/fi/5ajtqzg15vu4tpbqwc78d/slides.pdf?rlkey=zmdpkzht0o0ax9j9cu7y0aoir&st=l412imzl&dl=0)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/MayerLuziSiahkoohiEtAl_2024.bib)]

---

### Journal papers

**Multi-scale clustering and source separation of InSight mission seismic data**  
A. Siahkoohi, R. Morel, R. Balestriero, E. Allys, G. Sainton, T. Kawamura, and M. V. de Hoop  
*IEEE Transactions on Geoscience and Remote Sensing*, 2025, In print.  
[[pdf](https://arxiv.org/abs/2305.16189)]
[[code](https://github.com/alisiahkoohi/facvae)]
[[slides](https://www.dropbox.com/s/ycwu3y3jik33xpo/slides.pdf?dl=0)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/SiahkoohiMorelBalestrieroEtAl_2025.bib)]

**ASPIRE: Iterative amortized posterior inference for Bayesian inverse problems**  
R. Orozco, A. Siahkoohi, M. Louboutin, and F. J. Herrmann  
*Inverse Problems*, 41(4):045001, 2025.  
[[pdf](https://arxiv.org/abs/2405.05398)]
[[code](https://github.com/slimgroup/ASPIRE.jl)]
[[link](https://iopscience.iop.org/article/10.1088/1361-6420/adba3d)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/OrozcoSiahkoohiLouboutinEtAl_2025.bib)]




---

### Conference proceedings and presentations

**Self-consuming generative models go MAD**  
S. Alemohammad, J. Casco-Rodriguez, L. Luzi, A. I. Humayun, H. Babaei, D. LeJeune, A. Siahkoohi, and R. G. Baraniuk  
*The Twelfth International Conference on Learning Representations*, 2024.  
[[pdf](https://openreview.net/pdf?id=ShjMHfmPs0)]
[[extended pdf](https://arxiv.org/abs/2307.01850)]
[[poster](https://iclr.cc/media/PosterPDFs/ICLR%202024/18592.png?t=1714784281.722506)]
[[link](https://iclr.cc/virtual/2024/poster/18592)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/AlemohammadCasco_RodriguezLuziEtAl_2024.bib)]
[featured in the news
^[1](https://www.tomshardware.com/news/generative-ai-goes-mad-when-trained-on-artificial-data-over-five-times),^
^[2](https://futurism.com/ai-trained-ai-generated-data),^
^[3](https://www.tweaktown.com/news/92328/scientists-make-ai-go-crazy-by-feeding-it-generated-content/),^
^[4](https://www.newscientist.com/article/2382519-ais-trained-on-ai-generated-images-produce-glitches-and-blurs/),^
^[5](https://www.cdotrends.com/story/18288/training-ai-outputs-generative-ai-mad/),^
^[6](https://futurism.com/ai-trained-ai-generated-data-interview),^
^[7](https://www.telegraph.co.uk/business/2024/02/01/why-ai-new-age-of-fake-news-and-disinformation/),^
^[8](https://finance.yahoo.com/news/ais-mad-cow-disease-problem-tramples-into-earnings-season-100005953.html),^
^[9](https://fortune.com/2024/04/18/linkedin-microsoft-collaborative-articles-generative-ai-feedback-loop-user-backlash/?456789),^
^[10](https://news.rice.edu/news/2024/breaking-mad-generative-ai-could-break-internet),^
^[11](https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html),^
^[12](https://futurism.com/ai-slowly-killing-itself),^
^[13](https://magazine.rice.edu/winter-2025/ais-mad-loops)^]  
[[self-consuming AI resources](https://dsp.rice.edu/ai-loops/)]


**Titan: Bringing the deep image prior to implicit representations**  
L. Luzi, D. LeJeune, A. Siahkoohi, S. Alemohammad, V. Saragadam, H. Babaei, N. Liu, Z. Wang, and R. G. Baraniuk  
*IEEE International Conference on Acoustics, Speech and Signal Processing*, pages 6165--6169, 2024.  
[[pdf](https://arxiv.org/abs/2211.00219)]
[[code](https://github.com/dlej/titan-implicit-prior)]
[[link](https://ieeexplore.ieee.org/document/10446136)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/LuziLeJeuneSiahkoohiEtAl_2024.bib)]

**Conditional score-based diffusion models for Bayesian inference in infinite dimensions**  
L. Baldassari, A. Siahkoohi, J. Garnier, K. Sølna, and M. V. de Hoop  
*Advances in Neural Information Processing Systems*, volume 36, pages 24262--24290, 2023.  
[[pdf](https://papers.nips.cc/paper_files/paper/2023/file/4c79c359b3c5f077c0b955f93cb0f53e-Paper-Conference.pdf)]
[[slides](https://www.dropbox.com/scl/fi/bmgnbex0zcf575fjgzybu/slides.pdf?rlkey=2rd9nhc4a6tt8s65lk5sqbz2r&dl=0)]
[[poster](https://www.dropbox.com/scl/fi/7t9p0gogw6g7dmn8u52c6/poster.pdf?rlkey=sftpfelbglvrpi4lkn6tgp31q&dl=0)]
[[code](https://github.com/alisiahkoohi/csgm)]
[[link](https://papers.nips.cc/paper_files/paper/2023/hash/4c79c359b3c5f077c0b955f93cb0f53e-Abstract-Conference.html)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/BaldassariSiahkoohiGarnierEtAl_2023.bib)] [featured as a [Spotlight presentation](https://nips.cc/virtual/2023/events/spotlight-posters-2023)]



---

### Thesis

**Deep generative models for solving geophysical inverse problems**  
A. Siahkoohi  
*Ph.D. thesis*, Georgia Institute of Technology, 2022.  
[[pdf](https://slim.gatech.edu/Publications/Public/Thesis/2022/siahkoohi2022THdgmf/siahkoohi2022THdgmf.pdf)]
[[slides](https://slim.gatech.edu/Publications/Public/Thesis/2022/siahkoohi2022THdgmf/siahkoohi2022THdgmf_pres.pdf)]
[[link](http://hdl.handle.net/1853/67250)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/Siahkoohi_2022.bib)]

---

### Technical reports

**Taming score-based diffusion priors for infinite-dimensional nonlinear inverse problems**  
L. Baldassari, A. Siahkoohi, J. Garnier, K. Sølna, and M. V. de Hoop  
Technical Report arXiv:2405.15676, Rice University, 2024.  
[[pdf](https://arxiv.org/abs/2405.15676)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/BaldassariSiahkoohiGarnierEtAl_2024.bib)]

**Low-memory stochastic backpropagation with multi-channel randomized trace estimation**  
M. Louboutin, A. Siahkoohi, R. Wang, and F. J. Herrmann  
Technical Report arXiv:2106.06998, Georgia Institute of Technology, 2021.  
[[pdf](https://arxiv.org/abs/2106.06998)]
[[code](https://github.com/slimgroup/XConv)]
[[link](https://slim.gatech.edu/content/low-memory-stochastic-backpropagation-multi-channel-randomized-trace-estimation)]
[[bib](https://raw.githubusercontent.com/alisiahkoohi/alisiahkoohi.github.io/master/files/LouboutinSiahkoohiWangEtAl_2021.bib)]

---

## Miscellaneous

- "I wish you hadn't talked so much, it was distracting." --- Patrick Winston, [How to Speak](https://youtu.be/Unzc731iCUY)
- "No one cares about the inside of your head." --- Larry McEnerney, [The Craft of Writing Effectively](https://youtu.be/vtIzMaLkCaM)
